{"cells": [{"metadata": {"id": "c51fc7ca8ea042f286135d5419dca775"}, "cell_type": "markdown", "source": "# Load Packages"}, {"metadata": {"id": "3900265e7f9d49e2820aa857a17b1732"}, "cell_type": "code", "source": "import warnings\nwarnings.filterwarnings('ignore')\n\ntry:\n    from ibm_aigov_facts_client import AIGovFactsClient\nexcept:\n    !pip install -U ibm-aigov-facts-client\n    from ibm_aigov_facts_client import AIGovFactsClient", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Collecting ibm-aigov-facts-client\n  Downloading ibm_aigov_facts_client-1.0.44-py3-none-any.whl (140 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 140 kB 9.6 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: requests<3.0,>=2.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from ibm-aigov-facts-client) (2.28.1)\nCollecting mlflow-skinny==1.28.0\n  Downloading mlflow_skinny-1.28.0-py3-none-any.whl (3.5 MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.5 MB 24.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: pandas in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from ibm-aigov-facts-client) (1.3.4)\nRequirement already satisfied: numpy in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from ibm-aigov-facts-client) (1.23.4)\nCollecting docutils<0.16,>=0.10\n  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 547 kB 62.9 MB/s eta 0:00:01\n\u001b[?25hCollecting sqlparse>=0.3.1\n  Downloading sqlparse-0.4.3-py3-none-any.whl (42 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 42 kB 1.0 MB/s  eta 0:00:01\n\u001b[?25hCollecting timeout-decorator\n  Downloading timeout-decorator-0.5.0.tar.gz (4.8 kB)\nCollecting python-magic\n  Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\nRequirement already satisfied: ibm-cloud-sdk-core>=3.5.2 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from ibm-aigov-facts-client) (3.10.1)\nRequirement already satisfied: pyyaml<7,>=5.1 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (5.4.1)\nCollecting gitpython<4,>=2.1.0\n  Downloading GitPython-3.1.30-py3-none-any.whl (184 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 184 kB 58.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: protobuf<5,>=3.12.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (3.19.6)\nCollecting databricks-cli<1,>=0.8.7\n  Downloading databricks-cli-0.17.4.tar.gz (82 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 82 kB 277 kB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (8.0.4)\nRequirement already satisfied: packaging<22 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (21.3)\nRequirement already satisfied: entrypoints<1 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (0.3)\nRequirement already satisfied: pytz<2023 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (2021.3)\nRequirement already satisfied: cloudpickle<3 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from mlflow-skinny==1.28.0->ibm-aigov-facts-client) (1.6.0)\nCollecting importlib-metadata!=4.7.0,<5,>=3.7.0\n  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\nRequirement already satisfied: pyjwt>=1.7.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow-skinny==1.28.0->ibm-aigov-facts-client) (2.4.0)\nRequirement already satisfied: oauthlib>=3.1.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow-skinny==1.28.0->ibm-aigov-facts-client) (3.2.2)\nRequirement already satisfied: tabulate>=0.7.7 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow-skinny==1.28.0->ibm-aigov-facts-client) (0.8.9)\nRequirement already satisfied: six>=1.10.0 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow-skinny==1.28.0->ibm-aigov-facts-client) (1.16.0)\nCollecting gitdb<5,>=4.0.1\n  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 62 kB 902 kB/s  eta 0:00:01\n\u001b[?25hCollecting smmap<6,>=3.0.1\n  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.5.3 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from ibm-cloud-sdk-core>=3.5.2->ibm-aigov-facts-client) (2.8.2)\nRequirement already satisfied: zipp>=0.5 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<5,>=3.7.0->mlflow-skinny==1.28.0->ibm-aigov-facts-client) (3.10.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from packaging<22->mlflow-skinny==1.28.0->ibm-aigov-facts-client) (3.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from requests<3.0,>=2.0->ibm-aigov-facts-client) (2022.9.24)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from requests<3.0,>=2.0->ibm-aigov-facts-client) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from requests<3.0,>=2.0->ibm-aigov-facts-client) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from requests<3.0,>=2.0->ibm-aigov-facts-client) (1.26.12)\nBuilding wheels for collected packages: databricks-cli, timeout-decorator\n  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.17.4-py3-none-any.whl size=142875 sha256=f25849ca1486fa827c55814c0869e6e92e66c7723ccf6de62d57257f4c9cdf12\n  Stored in directory: /home/spark/shared/.cache/pip/wheels/b3/d4/24/ed7f421c3c600f3eee1a3a9e5c4aecc286a7622cac031918b7\n  Building wheel for timeout-decorator (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for timeout-decorator: filename=timeout_decorator-0.5.0-py3-none-any.whl size=5006 sha256=e6507036f088f46c9645befcd692692f04b5c34a53913c8b9b4cc0054222cb53\n  Stored in directory: /home/spark/shared/.cache/pip/wheels/5d/45/1d/a7d2bf8dfbdecd78983a3d422f2fe860316cfbae3f3b001ea5\nSuccessfully built databricks-cli timeout-decorator\nInstalling collected packages: smmap, gitdb, sqlparse, importlib-metadata, gitpython, databricks-cli, timeout-decorator, python-magic, mlflow-skinny, docutils, ibm-aigov-facts-client\n  Attempting uninstall: importlib-metadata\n    Found existing installation: importlib-metadata 5.0.0\n    Uninstalling importlib-metadata-5.0.0:\n      Successfully uninstalled importlib-metadata-5.0.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nautoai-libs 1.13.1 requires numpy<1.22,>=1.19.2; python_version >= \"3.9\", but you have numpy 1.23.4 which is incompatible.\u001b[0m\nSuccessfully installed databricks-cli-0.17.4 docutils-0.15.2 gitdb-4.0.10 gitpython-3.1.30 ibm-aigov-facts-client-1.0.44 importlib-metadata-4.13.0 mlflow-skinny-1.28.0 python-magic-0.4.27 smmap-5.0.0 sqlparse-0.4.3 timeout-decorator-0.5.0\n", "name": "stdout"}]}, {"metadata": {"id": "e55ce32b9e9641bf849619d66edf69c9"}, "cell_type": "code", "source": "import os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\nfrom project_lib import Project\n\n#sklearn \nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split,cross_val_score\nimport os, types\nfrom sklearn.metrics import f1_score\nimport numpy as np\nimport joblib\nimport datetime\nimport tempfile\n\n#WML\nfrom ibm_watson_machine_learning import APIClient\n\n#AiGovernance\nfrom ibm_aigov_facts_client import AIGovFactsClient,CloudPakforDataConfig\nimport sys", "execution_count": 2, "outputs": []}, {"metadata": {"id": "0b83abb19f1c44b7aeab68999f92146c"}, "cell_type": "markdown", "source": "# Load Data"}, {"metadata": {"id": "5347b64dde544c7d81f3307f79c8b1f4"}, "cell_type": "code", "source": "\nimport itc_utils.flight_service as itcfs\nreadClient = itcfs.get_flight_client()\n\nnb_data_request = {\n    'data_name': \"\"\"modeling_records_2022.csv\"\"\",\n    'interaction_properties': {\n        #'row_limit': 500,\n        'infer_schema': 'true',\n        'infer_as_varchar': 'false'\n    }\n}\n\nflightInfo = itcfs.get_flight_info(readClient, nb_data_request=nb_data_request)\n\ndf = itcfs.read_pandas_and_concat(readClient, flightInfo, timeout=240)\ndf.head(10)", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "   POSITION_CODE  DEPARTMENT_CODE  DAYS_WITH_COMPANY  COMMUTE_TIME  \\\n0           1200              200               1825            29   \n1           1200              200               2615             0   \n2           1300              320               1609            30   \n3           1300              320               2035            13   \n4           1400              380               1885            31   \n5           1400              380               3070            35   \n6           1400              380               1825             9   \n7           1500              300               2035            11   \n8           1500              300               2250             0   \n9           1600              330               1520            31   \n\n   AGE_BEGIN_PERIOD  GENDER_CODE  ATTRITION  PERIOD_TOTAL_DAYS  \\\n0                55        False      False                330   \n1                49        False      False                180   \n2                44         True      False                330   \n3                45        False      False                330   \n4                44        False      False                330   \n5                40        False      False                330   \n6                40         True      False                330   \n7                46        False      False                330   \n8                45         True      False                180   \n9                46        False      False                330   \n\n   STARTING_SALARY  ENDING_SALARY  ...  VACATION_DAYS_TAKEN  SICK_DAYS_TAKEN  \\\n0        159230.77      161538.46  ...                   28             10.5   \n1        181153.85      183846.15  ...                   15              4.0   \n2        129692.31      132923.08  ...                   20             15.0   \n3        146769.23      150461.54  ...                   28              8.0   \n4        146769.23      150461.54  ...                   26             11.5   \n5        157846.15      161538.46  ...                   19             12.5   \n6        146769.23      150461.54  ...                   20              9.0   \n7        132923.08      136153.85  ...                   10              9.0   \n8        150461.54      154153.85  ...                   10              4.0   \n9        143076.92      146769.23  ...                   26              9.5   \n\n   PROMOTIONS  NB_MANAGERS  DAYS_IN_POSITION  DAYS_SINCE_LAST_RAISE  \\\n0       False            1              1825                      0   \n1       False            1              2615                     60   \n2       False            1              1609                    150   \n3       False            1              2035                    210   \n4       False            1              1885                     60   \n5       False            1              3070                    150   \n6       False            1              1825                      0   \n7       False            1              2035                    210   \n8       False            1              2250                     60   \n9       False            1              1520                     60   \n\n   RANKING_CODE  OVERTIME  DBLOVERTIME  TRAVEL  \n0             3       0.0          0.0   False  \n1             3       0.0          0.0   False  \n2             3       0.0          0.0   False  \n3             3       0.0          0.0   False  \n4             3       0.0          0.0   False  \n5             3       0.0          0.0   False  \n6             3       0.0          0.0   False  \n7             3       0.0          0.0   False  \n8             3       0.0          0.0   False  \n9             3       0.0          0.0   False  \n\n[10 rows x 23 columns]", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>POSITION_CODE</th>\n      <th>DEPARTMENT_CODE</th>\n      <th>DAYS_WITH_COMPANY</th>\n      <th>COMMUTE_TIME</th>\n      <th>AGE_BEGIN_PERIOD</th>\n      <th>GENDER_CODE</th>\n      <th>ATTRITION</th>\n      <th>PERIOD_TOTAL_DAYS</th>\n      <th>STARTING_SALARY</th>\n      <th>ENDING_SALARY</th>\n      <th>...</th>\n      <th>VACATION_DAYS_TAKEN</th>\n      <th>SICK_DAYS_TAKEN</th>\n      <th>PROMOTIONS</th>\n      <th>NB_MANAGERS</th>\n      <th>DAYS_IN_POSITION</th>\n      <th>DAYS_SINCE_LAST_RAISE</th>\n      <th>RANKING_CODE</th>\n      <th>OVERTIME</th>\n      <th>DBLOVERTIME</th>\n      <th>TRAVEL</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1200</td>\n      <td>200</td>\n      <td>1825</td>\n      <td>29</td>\n      <td>55</td>\n      <td>False</td>\n      <td>False</td>\n      <td>330</td>\n      <td>159230.77</td>\n      <td>161538.46</td>\n      <td>...</td>\n      <td>28</td>\n      <td>10.5</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1825</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1200</td>\n      <td>200</td>\n      <td>2615</td>\n      <td>0</td>\n      <td>49</td>\n      <td>False</td>\n      <td>False</td>\n      <td>180</td>\n      <td>181153.85</td>\n      <td>183846.15</td>\n      <td>...</td>\n      <td>15</td>\n      <td>4.0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>2615</td>\n      <td>60</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1300</td>\n      <td>320</td>\n      <td>1609</td>\n      <td>30</td>\n      <td>44</td>\n      <td>True</td>\n      <td>False</td>\n      <td>330</td>\n      <td>129692.31</td>\n      <td>132923.08</td>\n      <td>...</td>\n      <td>20</td>\n      <td>15.0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1609</td>\n      <td>150</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1300</td>\n      <td>320</td>\n      <td>2035</td>\n      <td>13</td>\n      <td>45</td>\n      <td>False</td>\n      <td>False</td>\n      <td>330</td>\n      <td>146769.23</td>\n      <td>150461.54</td>\n      <td>...</td>\n      <td>28</td>\n      <td>8.0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>2035</td>\n      <td>210</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1400</td>\n      <td>380</td>\n      <td>1885</td>\n      <td>31</td>\n      <td>44</td>\n      <td>False</td>\n      <td>False</td>\n      <td>330</td>\n      <td>146769.23</td>\n      <td>150461.54</td>\n      <td>...</td>\n      <td>26</td>\n      <td>11.5</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1885</td>\n      <td>60</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1400</td>\n      <td>380</td>\n      <td>3070</td>\n      <td>35</td>\n      <td>40</td>\n      <td>False</td>\n      <td>False</td>\n      <td>330</td>\n      <td>157846.15</td>\n      <td>161538.46</td>\n      <td>...</td>\n      <td>19</td>\n      <td>12.5</td>\n      <td>False</td>\n      <td>1</td>\n      <td>3070</td>\n      <td>150</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1400</td>\n      <td>380</td>\n      <td>1825</td>\n      <td>9</td>\n      <td>40</td>\n      <td>True</td>\n      <td>False</td>\n      <td>330</td>\n      <td>146769.23</td>\n      <td>150461.54</td>\n      <td>...</td>\n      <td>20</td>\n      <td>9.0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1825</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1500</td>\n      <td>300</td>\n      <td>2035</td>\n      <td>11</td>\n      <td>46</td>\n      <td>False</td>\n      <td>False</td>\n      <td>330</td>\n      <td>132923.08</td>\n      <td>136153.85</td>\n      <td>...</td>\n      <td>10</td>\n      <td>9.0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>2035</td>\n      <td>210</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1500</td>\n      <td>300</td>\n      <td>2250</td>\n      <td>0</td>\n      <td>45</td>\n      <td>True</td>\n      <td>False</td>\n      <td>180</td>\n      <td>150461.54</td>\n      <td>154153.85</td>\n      <td>...</td>\n      <td>10</td>\n      <td>4.0</td>\n      <td>False</td>\n      <td>1</td>\n      <td>2250</td>\n      <td>60</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1600</td>\n      <td>330</td>\n      <td>1520</td>\n      <td>31</td>\n      <td>46</td>\n      <td>False</td>\n      <td>False</td>\n      <td>330</td>\n      <td>143076.92</td>\n      <td>146769.23</td>\n      <td>...</td>\n      <td>26</td>\n      <td>9.5</td>\n      <td>False</td>\n      <td>1</td>\n      <td>1520</td>\n      <td>60</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows \u00d7 23 columns</p>\n</div>"}, "metadata": {}}]}, {"metadata": {"id": "e3f5ae3f-50ab-4464-a6c7-e3fa6d41735a"}, "cell_type": "code", "source": "from sklearn.model_selection import train_test_split\n\nX = df.drop(['ATTRITION'], axis=1)  # Features\ny = df['ATTRITION']  # Labels\n\n# Split dataset into training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15) # 85% training and 15% test", "execution_count": null, "outputs": []}, {"metadata": {"id": "6ffc094b-4a20-435f-b897-4591b6fc17a3"}, "cell_type": "code", "source": "X.columns.tolist()", "execution_count": null, "outputs": []}, {"metadata": {"id": "9e203a7b-93bc-40ed-a9f6-2add3e5b88e0"}, "cell_type": "markdown", "source": "The cell below tells the Watson Machine Learning client to save the models in the current project. If you receive an error here, it is likely because you did not correctly set your project ID at the beginning of the notebook."}, {"metadata": {"id": "c7d7918e-42ee-4b22-8a61-e39b5cf49aca"}, "cell_type": "markdown", "source": "The following cell provides connection information to the model training data, which will be stored with the model and in FactSheets. You could use the Cloud Object Storage information for this particular project by changing the credentials to match those from above where you inserted the file to code, but for simplicity's sake, you will use a pre-existing file."}, {"metadata": {"id": "e94484c0-2b75-4e0e-bc81-68c46327d071"}, "cell_type": "markdown", "source": "training_data_references = [\n                {\n                    \"id\": \"attrition\",\n                    \"type\": \"s3\",\n                    \"connection\": {\n                        \"access_key_id\": \"yqcPbWZ0AQPHleHVerrR4Wx5e9pymBdMgydbEra5zCif\",\n                        \"endpoint_url\": \"https://s3.us.cloud-object-storage.appdomain.cloud\",\n                        \"resource_instance_id\": \"crn:v1:bluemix:public:cloud-object-storage:global:a/7d8b3c34272c0980d973d3e40be9e9d2:2883ef10-23f1-4592-8582-2f2ef4973639::\"\n                    },\n                    \"location\": {\n                        \"bucket\": \"faststartlab-donotdelete-pr-nhfd4jnhlxgpc7\",\n                        \"path\": \"modeling_records_2022.csv\"\n                    },\n                    \"schema\": {\n                        \"id\": \"training_schema\",\n                        \"fields\": [\n                            {\"name\": \"POSITION_CODE\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"DEPARTMENT_CODE\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"DAYS_WITH_COMPANY\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"COMMUTE_TIME\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"AGE_BEGIN_PERIOD\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"GENDER_CODE\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"PERIOD_TOTAL_DAYS\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"STARTING_SALARY\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"ENDING_SALARY\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"NB_INCREASES\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"BONUS\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"NB_BONUS\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"VACATION_DAYS_TAKEN\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"SICK_DAYS_TAKEN\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"PROMOTIONS\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"NB_MANAGERS\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"DAYS_IN_POSITION\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"DAYS_SINCE_LAST_RAISE\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"RANKING_CODE\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"OVERTIME\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"DBLOVERTIME\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"},\n                            {\"name\": \"TRAVEL\", \"nullable\": True, \"metadata\": {}, \"type\": \"double\"}\n                        ]\n                    }\n                }\n            ]"}, {"metadata": {"id": "7cfd1b92-b655-4376-bc96-d1b693f5d8c5"}, "cell_type": "markdown", "source": "The cell below will authenticate with the IBM FactSheet service using credentials you have already supplied and initialize FactSheet monitoring for this model. Note that Python notebooks in Watson Studio have full support for `pip install`, which allows you to add whatever libraries you need to the notebook environment. For example, if you wanted to use Python to parse command line arguments, you could run `!pip install argparse`.\n\nIf you receive an error related to the project access token, it is likely because you either did not insert the project access token as instructed at the beginning of the notebook, or did not run the cell after it was inserted. You will need to return to the beginning of the notebook, ensure the cell is inserted, and execute it."}, {"metadata": {"id": "92e6eae78946420c80fcaf0dcf435f72"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"id": "7a131b23d7b94a4d8318b98af206cdf5"}, "cell_type": "code", "source": "from ibm_watson_studio_lib import access_project_or_space\nwslib = access_project_or_space()\ntoken = wslib.auth.get_current_token()", "execution_count": null, "outputs": []}, {"metadata": {"id": "bdc5b11675a143e5942bd3f74efd38d5"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"id": "97b9684a6ddd456a8b5bca3ab239cc2c"}, "cell_type": "markdown", "source": "### Setup WML Client"}, {"metadata": {"id": "a0674814f5814dda83fa76102de187ee"}, "cell_type": "code", "source": "# @hidden_cell\nusername = 'ritchie'\npassword = 'Enigma'\nurl = 'https://internal-nginx-svc:12443'\n\nwml_credentials = {\n    \"username\": username,\n    \"password\": password,\n    \"url\": url,\n    \"instance_id\": 'openshift',\n    \"version\": '4.6'\n}\n\nfrom ibm_watson_machine_learning import APIClient\nwml_client = APIClient(wml_credentials)", "execution_count": null, "outputs": []}, {"metadata": {"id": "2b4939d24f84459e8417fc50087863b4"}, "cell_type": "markdown", "source": "### Setup FactSheet Client"}, {"metadata": {"id": "5bee466bf4c94a3f995b81c4810da27e"}, "cell_type": "code", "source": "# @hidden_cell\nfrom ibm_aigov_facts_client import AIGovFactsClient,CloudPakforDataConfig\ncpd_creds=CloudPakforDataConfig(service_url=\"https://internal-nginx-svc:12443\",\n    username=\"ritchie\",\n    password=\"Enigma\")\n\nCPD_URL=os.environ['RUNTIME_ENV_APSX_URL'][len('https://api.'):]\nPROJECT_UID= os.environ['PROJECT_ID']\nCONTAINER_ID=PROJECT_ID\nCONTAINER_TYPE='project'\nEXPERIMENT_NAME='predictive_attrition3'\n\nwml_client.set.default_project(PROJECT_ID)", "execution_count": null, "outputs": []}, {"metadata": {"id": "9d5b5697f3e348798863bb1434abbf89"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"id": "75794e8cbb54463282166a9b5b8f20ff"}, "cell_type": "code", "source": "#Facts Client\nfacts_client = AIGovFactsClient(cloud_pak_for_data_configs=cpd_creds, experiment_name=EXPERIMENT_NAME,container_type=\"project\",container_id=CONTAINER_ID)", "execution_count": null, "outputs": []}, {"metadata": {"id": "dcba408847ae413c89e15cbf44da3e80"}, "cell_type": "markdown", "source": "## Define Software Specifications & Train Model"}, {"metadata": {"id": "3f1b40b527c544abb213315ae8da5d92"}, "cell_type": "code", "source": "fields=X_train.columns.tolist()\nmetadata_dict = {'target_col' : 'ATTRITION', 'fields':fields}", "execution_count": null, "outputs": []}, {"metadata": {"id": "bcc75f39bcf4416ea75b66e796611e09"}, "cell_type": "code", "source": "import sklearn\nsklearn.__version__\n\n#https://dataplatform.cloud.ibm.com/docs/content/wsj/wmls/wmls-deploy-python-types.html", "execution_count": null, "outputs": []}, {"metadata": {"id": "91616e73e96e43ad894a22fdf5204f7a"}, "cell_type": "code", "source": "#Show Supported Frameworks\nwml_client.software_specifications.list(10)", "execution_count": null, "outputs": []}, {"metadata": {"id": "6b02995075a04c74944f41305da81f21"}, "cell_type": "code", "source": "software_spec_uid = wml_client.software_specifications.get_id_by_name(\"runtime-22.1-py3.9\")\nprint(\"Software Specification ID: {}\".format(software_spec_uid))\n\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "d7cad6ec17b44bb5b4105cff42937507"}, "cell_type": "code", "source": "\nmetadata = {\n            wml_client.repository.ModelMetaNames.NAME: 'Random Forrest',\n            wml_client.repository.ModelMetaNames.TYPE: 'scikit-learn_1.0',\n            wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n}\n\nfacts_client.export_facts.prepare_model_meta(wml_client=wml_client,meta_props=metadata)", "execution_count": null, "outputs": []}, {"metadata": {"id": "882afc8b79f341c28fa10ce8865154da"}, "cell_type": "code", "source": "from sklearn.ensemble import RandomForestClassifier\n\n#Create a Gaussian Classifier\nclf = RandomForestClassifier(n_estimators=50)\n\n#Train the model using the training sets y_pred=clf.predict(X_test)\nclf.fit(X_train,y_train)\n\ny_pred = clf.predict(X_test)", "execution_count": null, "outputs": []}, {"metadata": {"id": "1a1ecb47451e4e72817575b79b3929ed"}, "cell_type": "code", "source": "from sklearn import metrics\nimport pandas as pd\n# Model Accuracy, how often is the classifier correct?\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))", "execution_count": null, "outputs": []}, {"metadata": {"id": "45dbaad09e9b432fa3c42470d2cb07bb"}, "cell_type": "code", "source": "feature_imp = pd.Series(clf.feature_importances_,index=X.columns).sort_values(ascending=False)\nfeature_imp", "execution_count": null, "outputs": []}, {"metadata": {"id": "d93a948ebdc849f8892f587d1b2d9838"}, "cell_type": "code", "source": "facts_client.runs.list_runs_by_experiment('1')", "execution_count": null, "outputs": []}, {"metadata": {"id": "b6dcd5d9-e1f8-4dc5-9563-b152045d632a"}, "cell_type": "markdown", "source": "The next three cells fit the data the the model using a Random Forest classifier, run predictions on the test data, and then print out the accuracy for how the model did on the test data. Finally, the notebook calculates and displays feature importance. For more information on Random Forest classifiers, see [here](https://www.ibm.com/cloud/learn/random-forest)."}, {"metadata": {"id": "34c454cf-f19a-4b1e-a8f2-94a359dd40fd"}, "cell_type": "markdown", "source": "The next three cells export data from the model you just created to the FactSheet. The first lists experiments tracked by FactSheets. The second writes the URL and other info on this notebook as custom data to the FactSheet. Note that any data can be written to the FactSheet that might be helpful for model validators."}, {"metadata": {"id": "ad802ec9-914d-4d60-aaa2-c57b9bb8e1df"}, "cell_type": "code", "source": "nb_name = \"attrition model creation and deployment\"\nnb_asset_id = \"tbd\"\nnb_asset_url = \"https://\" + CPD_URL + \"/analytics/notebooks/v2/\" + nb_asset_id + \"?projectid=\" + PROJECT_UID + \"&context=cpdaas\"\n\nlatestRunId = facts_client.runs.list_runs_by_experiment('1').sort_values('start_time').iloc[-1]['run_id']\nfacts_client.runs.set_tags(latestRunId, {\"Notebook name\": nb_name, \"Notebook id\": nb_asset_id, \"Notebook URL\" : nb_asset_url})\nfacts_client.export_facts.export_payload(latestRunId)", "execution_count": null, "outputs": []}, {"metadata": {"id": "7bc733e8-9ed0-443d-a4e5-b3d901aa4002"}, "cell_type": "code", "source": "RUN_ID=facts_client.runs.get_current_run_id()\nfacts_client.export_facts.export_payload(RUN_ID)", "execution_count": null, "outputs": []}, {"metadata": {"id": "e863f31d-dfb3-4357-bf63-d0498731f82d"}, "cell_type": "markdown", "source": "Finally, the model is stored to the project with all of the metadata defined above."}, {"metadata": {"id": "d0ef1696-ce51-4e74-9412-3937222637c8"}, "cell_type": "code", "source": "print(\"Storing model...\")\npublished_model_details = wml_client.repository.store_model(\n    model=clf, \n    meta_props=metadata,\n    training_target=['ATTRITION'],\n    training_data=X)\nmodel_uid = wml_client.repository.get_model_id(published_model_details)\n\nprint(\"Done\")\nprint(\"Model ID: {}\".format(model_uid))", "execution_count": null, "outputs": []}, {"metadata": {"id": "f2805c98ede74f259e77e5cfae285f41"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"id": "ec49c307839342d182f6eda78031b101"}, "cell_type": "markdown", "source": "# Spark Model"}, {"metadata": {"id": "f4990ccc-46c5-41e0-965e-87dc0444fc0e"}, "cell_type": "markdown", "source": "Next, the notebook uses Apache Spark to create a second model. Because you specified a Spark environment when you created this notebook, the `pyspark` runtime will be available without needing to be installed via `pip`."}, {"metadata": {"id": "0156728d-9c5c-46a4-a3ce-749bcdacb3b7"}, "cell_type": "code", "source": "try:\n    from pyspark.sql import SparkSession\nexcept:\n    print('Error: Spark runtime is missing. If you are using Watson Studio change the notebook runtime to Spark by clicking \\\n    the Vew notebook info button above (the lowercase i in a circle). Click on the Environment tab and use the Environment \\\n    definition dropdown to select an environment with Spark and Python.')\n    raise\nspark.version", "execution_count": null, "outputs": []}, {"metadata": {"id": "7466683477474b07a4f8381300e927b5"}, "cell_type": "code", "source": "import itc_utils.flight_service as itcfs\n\nfrom pyspark.sql import SparkSession\nspark = SparkSession.builder.getOrCreate()\nspark.conf.set(\"spark.sql.execution.arrow.pyspark.enabled\", \"true\")\n\nreadClient = itcfs.get_flight_client()\n\nnb_data_request = {\n    'data_name': \"\"\"modeling_records_2022.csv\"\"\",\n    'interaction_properties': {\n        #'row_limit': 500,\n        'infer_schema': 'true',\n        'infer_as_varchar': 'false'\n    }\n}\n\nflightInfo = itcfs.get_flight_info(readClient, nb_data_request=nb_data_request)\n\ndf_data_2 = itcfs.read_pandas_and_concat(readClient, flightInfo, timeout=240)\ndf_data_2 = spark.createDataFrame(df_data_2)\ndf_data_2.show(10)\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "5fec9dd2-de7f-4e6b-acef-39c330ac7e79"}, "cell_type": "markdown", "source": "Similar to the `sklearn` model, you need to specify metadata for the spark model."}, {"metadata": {"id": "ad8c1299-b6b2-4204-8af4-2ba7d9cf96f4"}, "cell_type": "code", "source": "software_spec_uid = wml_client.software_specifications.get_id_by_name('spark-mllib_3.3')\nprint(\"Software Specification ID: {}\".format(software_spec_uid))\n\nmeta_props1 = {\n            wml_client.repository.ModelMetaNames.NAME: 'Attrition Challenger \u2013 Spark',\n            wml_client.repository.ModelMetaNames.TYPE: 'mllib_3.3',\n            wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: software_spec_uid\n}\n\nfacts_client.export_facts.prepare_model_meta(wml_client=wml_client,meta_props=meta_props1)", "execution_count": null, "outputs": []}, {"metadata": {"id": "8000d772b5d644838483c1a6099dd4cf"}, "cell_type": "markdown", "source": "software_spec_uid = wml_client.software_specifications.get_id_by_name(\"spark-mllib_3.3\")\nprint(\"Software Specification ID: {}\".format(software_spec_uid))\n\n\nmodel_props = {\n    wml_client._models.ConfigurationMetaNames.NAME:\"{}\".format(\"attrition challenger - spark\"),\n    wml_client._models.ConfigurationMetaNames.TYPE: \"mllib_3.3\",\n    wml_client._models.ConfigurationMetaNames.SOFTWARE_SPEC_UID: software_spec_uid,\n    wml_client._models.ConfigurationMetaNames.TRAINING_DATA_REFERENCES: training_data_references,\n    wml_client._models.ConfigurationMetaNames.LABEL_FIELD: \"ATTRITION\"\n}\n\nfacts_client.export_facts.prepare_model_meta(wml_client=wml_client,meta_props=model_props)"}, {"metadata": {"id": "fc7d437159384a0899bc9490015cbfde"}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}, {"metadata": {"id": "b2e42466-ba9d-4806-ac38-ac58e2376a3f"}, "cell_type": "code", "source": "from pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml import Pipeline, Model", "execution_count": null, "outputs": []}, {"metadata": {"id": "bc1154f7-29d0-4b6e-a4bc-ee05d2f9be3b"}, "cell_type": "markdown", "source": "For the second model, you will create a Gradient Boosted Tree classifier. For more information on Gradient Boosting, see [here](https://www.ibm.com/cloud/learn/boosting)."}, {"metadata": {"id": "91e8172a-0115-435f-b959-914230fba043"}, "cell_type": "code", "source": "from pyspark.sql.types import FloatType\nfor field in fields:\n    df_data_2=df_data_2.withColumn(field,df_data_2[field].cast(\"float\").alias(field))\ndf_data_2=df_data_2.withColumn('ATTRITION',df_data_2['ATTRITION'].cast(\"int\").alias('ATTRITTION'))\ndf_data_2.take(5)", "execution_count": null, "outputs": []}, {"metadata": {"id": "cde29502-faf3-4b97-936c-0c9df734bbb3"}, "cell_type": "code", "source": "va = VectorAssembler(inputCols = fields, outputCol='features')\nva_df = va.transform(df_data_2)\nva_df = va_df.select(['features', 'ATTRITION'])\nva_df.show(3)", "execution_count": null, "outputs": []}, {"metadata": {"id": "433dc10d-9d00-44b7-a40b-f2b88fba5a3f"}, "cell_type": "code", "source": "gbtc = GBTClassifier(labelCol=\"ATTRITION\", maxIter=20)\n\npipeline = Pipeline(stages=[va, gbtc])", "execution_count": null, "outputs": []}, {"metadata": {"id": "d27fd74f-f27f-4685-9ba2-7f55e5ca7bc2"}, "cell_type": "code", "source": "split_data = df_data_2.randomSplit([0.8, 0.2], 24)\ntrain_data = split_data[0]\ntest_data = split_data[1]\n\nprint(\"Number of training records: \" + str(train_data.count()))\nprint(\"Number of testing records : \" + str(test_data.count()))", "execution_count": null, "outputs": []}, {"metadata": {"id": "a4364b0e-6133-4919-bb63-31a4fd41d94c"}, "cell_type": "code", "source": "spark_model = pipeline.fit(train_data)\n\npred = spark_model.transform(test_data)\npred.show(3) ", "execution_count": null, "outputs": []}, {"metadata": {"id": "1a5350a2-736f-49bb-9114-6d5a1fd34c7c"}, "cell_type": "code", "source": "evaluator = BinaryClassificationEvaluator()\nevaluator.setLabelCol(\"ATTRITION\")\nprint(\"Test Area Under ROC: \" + str(evaluator.evaluate(pred, {evaluator.metricName: \"areaUnderROC\"})))", "execution_count": null, "outputs": []}, {"metadata": {"id": "81927afd24c74b8c9237ce0a89f7187b"}, "cell_type": "code", "source": "#Specify ML Model and Save it into WML\nsofware_spec_uid = wml_client.software_specifications.get_id_by_name(\"spark-mllib_3.3\")\n\n\n\n\nmetadata = {\n            wml_client.repository.ModelMetaNames.NAME: 'Spark GBT',\n            wml_client.repository.ModelMetaNames.TYPE: 'mllib_3.3',\n            wml_client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: sofware_spec_uid\n}\n\npublished_model = wml_client.repository.store_model(\n    model=spark_model,\n    meta_props=meta_props1,\n    training_target=['ATTRITION'],\n    training_data=train_data,\n    pipeline=pipeline\n)", "execution_count": null, "outputs": []}, {"metadata": {"id": "cb9f440ec16e4d628af0cbbec884a079"}, "cell_type": "code", "source": "print(\"Storing model...\")\npublished_model_details = wml_client.repository.store_model(\n    model=clf, \n    meta_props=metadata,\n    training_target=['ATTRITION'],\n    training_data=X)\nmodel_uid = wml_client.repository.get_model_id(published_model_details)\n\nprint(\"Done\")\nprint(\"Model ID: {}\".format(model_uid))", "execution_count": null, "outputs": []}, {"metadata": {"id": "44bb357f-98ed-46ff-80de-e185290590d2"}, "cell_type": "code", "source": "print(\"Storing spark model...\")\npublished_model_details = wml_client.repository.store_model(\n    model=spark_model, \n    meta_props=meta_props1,\n    training_target=['ATTRITION'],\n    training_data=train_data,\n    pipeline=pipeline\n)\nmodel_uid = wml_client.repository.get_model_id(published_model_details)\n\nprint(\"Done\")\nprint(\"Model ID: {}\".format(model_uid))\n", "execution_count": null, "outputs": []}, {"metadata": {"id": "7d8680b3-cb05-4205-b5fd-9e2553abb899"}, "cell_type": "markdown", "source": "# Congratulations!\n\nYou have completed this notebook. You can now return to the [Data and AI Live Demos lab page](https://cp4d-outcomes.techzone.ibm.com/data-fabric-lab/trusted-ai) and continue with the lab."}], "metadata": {"kernelspec": {"name": "python39", "display_name": "Python 3.9 with Spark", "language": "python3"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}